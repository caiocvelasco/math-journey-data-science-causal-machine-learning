---
author: "Caio Velasco"
date: today
---

> üáßüá∑ **Portuguese Version:** [Go to PT](../pt/index.html)

This is my structured learning roadmap to prepare for research in **causal machine learning** with mathematical rigor.

Here you can find both **mathematical foundations** and **applications**.

---

## Journey Phases

### Phase 1 ‚Äì Logic & Set Theory
**Goal:** Build comfort with the *language of mathematics*.  
- Proof techniques: direct, contrapositive, contradiction, induction.  
- Sets and families of sets, Cartesian products, power sets.  
- Functions: injective, surjective, bijective.  
- Relations: equivalence relations, partial orders.  
- Cardinality: countable vs. uncountable sets.  

**Theory Output:**
- Sentential logic (Velleman Ch. 1)
- Predicate logic & quantifiers (Ch. 2)
- Proof techniques (direct, contrapositive, contradiction, induction) (Ch. 3)
- Sets, relations, functions (Ch. 4‚Äì6)
- Countability, infinity (Ch. 9 selected, Tao‚Äôs appendix)  

**Application Project:** 
- SQL/database operations as set theory (joins, unions, intersections).
- Prove/discuss equivalences (e.g., idempotency: SELECT DISTINCT twice = once)

**References:**  
- Velleman ‚Äì *How to Prove It*  
- Enderton ‚Äì *Set Theory*  

---

### Phase 2 ‚Äì Real Analysis
**Goal:** Rigorous calculus and convergence.  
- Sequences, series, limits.  
- Continuity, compactness, connectedness.  
- Differentiation, Riemann integration (with rigor).  
- Uniform convergence.  

**Theory Output:** Œµ‚ÄìŒ¥ proofs, compactness in ‚Ñù, uniform convergence examples.  
**Application Project:** Gradient descent convergence demo; connect convexity to logistic regression loss.  

**References:**  
- Rudin ‚Äì *Principles of Mathematical Analysis* (Baby Rudin)  
- Tao ‚Äì *Analysis I*  

---

### Phase 3 ‚Äì Topology & Measure Theory
**Goal:** Learn the structures that underlie probability theory.  
- Metric spaces, open/closed sets.  
- Compactness and product spaces.  
- œÉ-algebras, measurable functions.  
- Lebesgue measure and integration.  
- Convergence theorems: MCT, DCT.  

**Theory Output:** Worked examples of œÉ-algebras, Lebesgue integral, and convergence theorems.  
**Application Project:** Fraud detection via Monte Carlo ‚Äî rare events and measure-zero sets in anomaly detection.  

**References:**  
- Munkres ‚Äì *Topology*  
- Schilling ‚Äì *Measures, Integrals and Martingales*  

---

### Phase 4 ‚Äì Probability
**Goal:** Define probability rigorously √† la Kolmogorov.  
- Probability spaces and random variables as measurable functions.  
- Distributions, independence, product measures.  
- Conditional expectation as L¬≤ projection.  
- Laws of large numbers, central limit theorem.  
- Intro to martingales.  

**Theory Output:** Probability space construction, LLN/CLT proofs, conditional expectation as projection.  
**Application Project:** A/B testing simulation ‚Äî CLT and confidence intervals for conversion rates.  

**References:**  
- Durrett ‚Äì *Probability: Theory and Examples*  
- Klenke ‚Äì *Probability Theory*  

---

### Phase 5 ‚Äì Mathematical Statistics
**Goal:** Connect probability ‚Üí inference.  
- Point estimation: MLE, method of moments.  
- Properties: unbiasedness, consistency, efficiency.  
- Hypothesis testing and likelihood ratio tests.  
- Asymptotic results: convergence in probability/distribution, delta method.  

**Theory Output:** Consistency of MLE, hypothesis testing framework, asymptotic normality proofs.  
**Application Project:** Logistic regression for churn prediction ‚Äî prove Bernoulli MLE consistency, simulate convergence, apply to real dataset.  

**References:**  
- Casella & Berger ‚Äì *Statistical Inference*  

---

### Phase 6 ‚Äì Causality
**Goal:** Enter causal inference with strong mathematical foundations.  
- Pearl‚Äôs Structural Causal Models & do-calculus.  
- Rubin‚Äôs potential outcomes framework.  
- Invariant causal prediction (Peters, Janzing, Sch√∂lkopf).  
- Identifiability proofs.  
- Axiomatic frameworks (Park & Muandet).  

**Theory Output:** Worked proofs of identifiability, back-door/front-door criteria, do-calculus rules.  
**Application Project:** Uplift modeling for churn retention OR reproduction of Chernozhukov‚Äôs Double Machine Learning estimator with Python.  

**References:**  
- Pearl ‚Äì *Causality*  
- Peters, Janzing, Sch√∂lkopf ‚Äì *Elements of Causal Inference*  
- Chernozhukov et al. ‚Äì *Causal Machine Learning papers*  
