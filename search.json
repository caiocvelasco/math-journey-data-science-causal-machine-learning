[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Foundations of Data Science & Causal ML: A Mathematical Journey",
    "section": "",
    "text": "Journey Phases\nThis is my structured learning roadmap to prepare for research in causal machine learning with mathematical rigor.\nHere you can find both mathematical foundations and applications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Journey Phases</span>"
    ]
  },
  {
    "objectID": "index.html#journey-phases",
    "href": "index.html#journey-phases",
    "title": "Foundations of Data Science & Causal ML: A Mathematical Journey",
    "section": "",
    "text": "Phase 1 â€“ Logic & Set Theory\nGoal: Build comfort with the language of mathematics.\n- Proof techniques: direct, contrapositive, contradiction, induction.\n- Sets and families of sets, Cartesian products, power sets.\n- Functions: injective, surjective, bijective.\n- Relations: equivalence relations, partial orders.\n- Cardinality: countable vs.Â uncountable sets.\nTheory Output: - Sentential logic (Velleman Ch. 1) - Predicate logic & quantifiers (Ch. 2) - Proof techniques (direct, contrapositive, contradiction, induction) (Ch. 3) - Sets, relations, functions (Ch. 4â€“6) - Countability, infinity (Ch. 9 selected, Taoâ€™s appendix)\nApplication Project: - SQL/database operations as set theory (joins, unions, intersections). - Prove/discuss equivalences (e.g., idempotency: SELECT DISTINCT twice = once)\nReferences:\n- Velleman â€“ How to Prove It\n- Enderton â€“ Set Theory\n\n\n\nPhase 2 â€“ Real Analysis\nGoal: Rigorous calculus and convergence.\n- Sequences, series, limits.\n- Continuity, compactness, connectedness.\n- Differentiation, Riemann integration (with rigor).\n- Uniform convergence.\nTheory Output: Îµâ€“Î´ proofs, compactness in â„, uniform convergence examples.\nApplication Project: Gradient descent convergence demo; connect convexity to logistic regression loss.\nReferences:\n- Rudin â€“ Principles of Mathematical Analysis (Baby Rudin)\n- Tao â€“ Analysis I\n\n\n\nPhase 3 â€“ Topology & Measure Theory\nGoal: Learn the structures that underlie probability theory.\n- Metric spaces, open/closed sets.\n- Compactness and product spaces.\n- Ïƒ-algebras, measurable functions.\n- Lebesgue measure and integration.\n- Convergence theorems: MCT, DCT.\nTheory Output: Worked examples of Ïƒ-algebras, Lebesgue integral, and convergence theorems.\nApplication Project: Fraud detection via Monte Carlo â€” rare events and measure-zero sets in anomaly detection.\nReferences:\n- Munkres â€“ Topology\n- Schilling â€“ Measures, Integrals and Martingales\n\n\n\nPhase 4 â€“ Probability\nGoal: Define probability rigorously Ã  la Kolmogorov.\n- Probability spaces and random variables as measurable functions.\n- Distributions, independence, product measures.\n- Conditional expectation as LÂ² projection.\n- Laws of large numbers, central limit theorem.\n- Intro to martingales.\nTheory Output: Probability space construction, LLN/CLT proofs, conditional expectation as projection.\nApplication Project: A/B testing simulation â€” CLT and confidence intervals for conversion rates.\nReferences:\n- Durrett â€“ Probability: Theory and Examples\n- Klenke â€“ Probability Theory\n\n\n\nPhase 5 â€“ Mathematical Statistics\nGoal: Connect probability â†’ inference.\n- Point estimation: MLE, method of moments.\n- Properties: unbiasedness, consistency, efficiency.\n- Hypothesis testing and likelihood ratio tests.\n- Asymptotic results: convergence in probability/distribution, delta method.\nTheory Output: Consistency of MLE, hypothesis testing framework, asymptotic normality proofs.\nApplication Project: Logistic regression for churn prediction â€” prove Bernoulli MLE consistency, simulate convergence, apply to real dataset.\nReferences:\n- Casella & Berger â€“ Statistical Inference\n\n\n\nPhase 6 â€“ Causality\nGoal: Enter causal inference with strong mathematical foundations.\n- Pearlâ€™s Structural Causal Models & do-calculus.\n- Rubinâ€™s potential outcomes framework.\n- Invariant causal prediction (Peters, Janzing, SchÃ¶lkopf).\n- Identifiability proofs.\n- Axiomatic frameworks (Park & Muandet).\nTheory Output: Worked proofs of identifiability, back-door/front-door criteria, do-calculus rules.\nApplication Project: Uplift modeling for churn retention OR reproduction of Chernozhukovâ€™s Double Machine Learning estimator with Python.\nReferences:\n- Pearl â€“ Causality\n- Peters, Janzing, SchÃ¶lkopf â€“ Elements of Causal Inference\n- Chernozhukov et al.Â â€“ Causal Machine Learning papers",
    "crumbs": [
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Journey Phases</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html",
    "href": "chapters/01_ch01.html",
    "title": "Phase 1: Logic & Set Theory",
    "section": "",
    "text": "1. Sentential Logic\nMathematical Reasoning begins with logic. Proofs in analysis, probability, and statistics rely on the ability to manipulate statements rigorously, understand how they combine, and know when two statements are logically equivalent.\nFor example, in Causal Machine Learning, assumptions are often stated in logical form. For example:\nThus, before diving into analysis and probability, we establish a foundation in logic and set theory. This is important to formalize assumptions, express mathematical objects precisely, and build proofs with rigor.\nLogic gives us the language to connect premises and conclusions, while Set Theory gives us the structure to define universes of discourse, events, and probability spaces. Together, they form the toolkit we need to reason about identification, estimation, and inference, not only in Causal Machine Learning, but also in Data Science, AI, and any other field that depend on mathematics.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#statements-propositions-predicates-and-connectives",
    "href": "chapters/01_ch01.html#statements-propositions-predicates-and-connectives",
    "title": "Phase 1: Logic & Set Theory",
    "section": "1.1 Statements, Propositions, Predicates, and Connectives",
    "text": "1.1 Statements, Propositions, Predicates, and Connectives\nğŸ’¡Motivation\nLearning statements and connectives is like learning the alphabet of mathematics.\n- If you cannot distinguish valid statements, you cannot even start a proof.\nExample in causal inference:\n- \\(p\\): â€œTreatment is randomized.â€\n- \\(q\\): â€œIgnorability holds.â€\n- Then â€œIf treatment is randomized, then ignorability holdsâ€ is \\(p \\to q\\).\nWithout connectives, weâ€™d stay in informal language. With them, we can formalize statements and reason rigorously about consequences, such as proving that a set of assumptions implies consistency of an estimator, showing that ignorability implies identification of a treatment effect, or demonstrating that conditional independence leads to factorization of a probability distribution into simpler components.\nA Statement (or Proposition) is a declarative sentence that is either true or false.\n\nExample: â€œ3 is evenâ€ (false), â€œBarcelona is in Spainâ€ (true).\n\nA Predicate is like a â€œtemplateâ€ for a statement: it depends on a variable and becomes a statement once you specify the value. For example:\n\\(P(x): x &gt; 0\\)\n- \\(P(2)\\) â†’ â€œ2 &gt; 0â€ (true).\n- \\(P(-1)\\) â†’ â€œ-1 &gt; 0â€ (false).\nConnectives let us combine assumptions systematically. Logical connectives let us build compound statements:\n\nNegation: \\(\\lnot p\\) (â€œnot \\(p\\)â€)\n\nConjunction: \\(p \\land q\\) (â€œ\\(p\\) and \\(q\\)â€)\n\nDisjunction: \\(p \\lor q\\) (â€œ\\(p\\) or \\(q\\)â€)\n\nConditional: \\(p \\to q\\) (â€œif \\(p\\) then \\(q\\)â€)\n\nBiconditional: \\(p \\leftrightarrow q\\) (â€œ\\(p\\) if and only if \\(q\\)â€)\n\nThus:\n- Predicate: general template (open sentence, truth depends on a variable) -&gt; becomes true or false only when a variable is given a value.\n- Proposition/statement: instance of that template (closed sentence, definite truth) -&gt; something that is already true or false.\n- Connectives: operators that take simple propositions and form compound propositions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#truth-tables",
    "href": "chapters/01_ch01.html#truth-tables",
    "title": "Phase 1: Logic & Set Theory",
    "section": "1.2 Truth Tables",
    "text": "1.2 Truth Tables\nğŸ’¡Motivation Truth tables are the grammar checker of logic.\n- They allow us to test whether two statements are equivalent (so we can swap one for another in a proof, probably to make life easier).\n- They reveal tautologies (always true) and contradictions (always false).\n- They give a mechanical way to check validity of deductive arguments.\nExample in statistics:\n- â€œIf the data behave nicely (i.i.d. + finite variance), then the sample mean is reliable (it will converge to the true mean)â€ (\\(p \\to q\\)).\n- Equivalent contrapositive: â€œIf effect is not identifiable, then ignorability does not holdâ€ (\\(\\lnot q \\to \\lnot p\\)).\n- Truth tables prove these are the same, so you can flip perspectives safely in a paper.\nA truth table shows how the truth value of a compound statement depends on its parts.\nExample: Prove that an implication (\\(p \\to q\\)) is equivalent (\\(\\equiv\\)) to its contrapositive (\\(\\lnot q \\to \\lnot p\\)).\nWe want to show: \\(p \\to q \\;\\equiv\\; \\lnot q \\to \\lnot p\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\to q\\)\n\\(\\lnot q\\)\n\\(\\lnot p\\)\n\\(\\lnot q \\to \\lnot p\\)\n\n\n\n\nT\nT\nT\nF\nF\nT\n\n\nT\nF\nF\nT\nF\nF\n\n\nF\nT\nT\nF\nT\nT\n\n\nF\nF\nT\nT\nT\nT\n\n\n\nSince the last two columns match, the implication is equivalent to its contrapositive.\nThe Basic Connectives\nLogical connectives are rules for combining simpler statements into compound ones.\nHere are the five most common and some intuition:\n\nNegation: \\(\\lnot p\\) (â€œnot \\(p\\)â€)\n\nRule: Negation flips the truth value.\n\nIf \\(p\\) is true, \\(\\lnot p\\) is false.\n\nIf \\(p\\) is false, \\(\\lnot p\\) is true.\n\nExample:\n\\(p\\): â€œIt is raining.â€\n\\(\\lnot p\\): â€œIt is not raining.â€\n\n\nConjunction: \\(p \\land q\\) (â€œ\\(p\\) and \\(q\\)â€)\n\nRule: \\(p \\land q\\) is true only if both \\(p\\) and \\(q\\) are true.\nExample:\n\\(p\\): â€œIt is raining.â€\n\\(q\\): â€œI am carrying an umbrella.â€\n\\(p \\land q\\): â€œIt is raining and I am carrying an umbrella.â€\nTruth check: If either part fails, the whole conjunction is false.\n\n\nDisjunction: \\(p \\lor q\\) (â€œ\\(p\\) or \\(q\\)â€)\n\nRule: \\(p \\lor q\\) is true if at least one of \\(p, q\\) is true.\n(This is the inclusive or used in logic.)\nExample:\n\\(p\\): â€œI will drink coffee.â€\n\\(q\\): â€œI will drink tea.â€\n\\(p \\lor q\\): â€œI will drink coffee or tea (or both).â€\nNote: In everyday language, â€œorâ€ can be exclusive. Logic defaults to inclusive.\n\n\nConditional: \\(p \\to q\\) (â€œif \\(p\\) then \\(q\\)â€)\n\nRule: An implication is false only when \\(p\\) is true and \\(q\\) is false.\nIn all other cases, it is true.\nEquivalent form:\n\\[\np \\to q \\;\\equiv\\; \\lnot p \\lor q\n\\]\nExample:\n\\(p\\): â€œIt rains.â€\n\\(q\\): â€œThe ground is wet.â€\n\\(p \\to q\\): â€œIf it rains, then the ground is wet.â€\nCase analysis:Â \n\nIf it rains and the ground is wet â†’ the statement â€œIf it rains, then the ground is wetâ€ has been kept. Both the condition and the consequence hold, so the implication is true.\n\nIf it rains but the ground is not wet â†’ the statement has been broken. This is the only case where an implication is false: the condition was met but the promised result failed.\n\nIf it doesnâ€™t rain â†’ the statement never gets a chance to be tested. We cannot accuse it of being false, because the condition (â€œit rainsâ€) never happened. By definition, logic treats this as vacuously true: the promise has not been broken, since there was nothing to check.\n\nIf it doesnâ€™t rain and the ground is wet â†’ still vacuously true. The implication didnâ€™t say what should happen when it doesnâ€™t rain; the ground being wet for other reasons (sprinklers, a bucket of water, etc.) doesnâ€™t violate the promise.\n\n\nIntuition and goal of the conditional\nThe statement \\(p \\to q\\) is read â€œif \\(p\\) holds then \\(q\\) holdsâ€ or even â€œif \\(p\\) is true then \\(q\\) is true.â€Â  At first glance, this seems strange because we must also handle cases when \\(p\\) or \\(q\\) are false.Â  Why not just say it means â€œboth \\(p\\) and \\(q\\) are trueâ€?\nThe key is that an implication is really a promise or rule:\n- â€œWhenever \\(p\\) happens, \\(q\\) must also happen.â€\nSo we only judge the statement in the situations where the promise could actually be tested: when \\(p\\) is true.\n\nIf \\(p\\) is true and \\(q\\) is true â†’ the promise is kept â†’ the implication is true.\n\nIf \\(p\\) is true and \\(q\\) is false â†’ the promise is broken â†’ the implication is false.\n\nBut if \\(p\\) is false, the situation that was promised never arises. In those cases, the rule is not violated. By convention (and to make logical systems consistent), we treat the implication as vacuously true whenever \\(p\\) is false.\nThis explains why the truth table looks the way it does:\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\to q\\)\nExplanation\n\n\n\n\nT\nT\nT\npromise kept\n\n\nT\nF\nF\npromise broken\n\n\nF\nT\nT\nvacuously true (condition never triggered)\n\n\nF\nF\nT\nvacuously true (condition never triggered)\n\n\n\nWhy is this important?\nUnderstanding the conditional matters because:\n\nIt allows us to formalize logical rules like the contrapositive:\n\\[\np \\to q \\;\\equiv\\; \\lnot q \\to \\lnot p\n\\] which is central in proofs.\nIt prevents confusion when reading theorems:\n\nâ€œIf a sequence converges, then it is boundedâ€ (\\(p \\to q\\)).\n\nThis is not claiming that all bounded sequences converge; the truth table guarantees the direction of the promise is clear.\n\nIt highlights vacuous truth, which appears everywhere in math:\n\nâ€œAll unicorns have hornsâ€ is technically true, because there are no unicorns to provide a counterexample.\n\nSimilarly, in probability, if an event has probability zero, conditional statements given that event can be vacuously true.\n\n\nBy appreciating this structure, the reader sees why the conditional is defined with its somewhat surprising truth table: it captures the idea of a promise that can only be broken in one very specific case.\n\nBiconditional: \\(p \\leftrightarrow q\\) (â€œ\\(p\\) if and only if \\(q\\)â€)\n\nRule: \\(p \\leftrightarrow q\\) is true exactly when \\(p\\) and \\(q\\) have the same truth value\n(both true or both false).\nEquivalent form:\n\\[\np \\leftrightarrow q \\;\\equiv\\; (p \\to q) \\land (q \\to p)\n\\]\nExample:\n\\(p\\): â€œToday is Saturday.â€\n\\(q\\): â€œTomorrow is Sunday.â€\n\\(p \\leftrightarrow q\\): â€œToday is Saturday if and only if tomorrow is Sunday.â€\nCase analysis:\n\nIf both \\(p\\) and \\(q\\) are true â†’ the biconditional is true (both directions of the promise hold).\n\nIf \\(p\\) is true but \\(q\\) is false â†’ false, because one direction of the â€œif and only ifâ€ fails.\n\nIf \\(p\\) is false but \\(q\\) is true â†’ false, for the same reason.\n\nIf both \\(p\\) and \\(q\\) are false â†’ true, because they match in value (both false).\n\n\nThis explains why the truth table looks like this:\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\leftrightarrow q\\)\nExplanation\n\n\n\n\nT\nT\nT\nboth true â†’ promise kept\n\n\nT\nF\nF\nmismatch â†’ one direction fails\n\n\nF\nT\nF\nmismatch â†’ one direction fails\n\n\nF\nF\nT\nboth false â†’ they match\n\n\n\nIntuition and goal of the biconditional\nThe biconditional expresses equivalence: \\(p\\) and \\(q\\) â€œstand or fall together.â€\nIt is stronger than a one-way implication: both \\(p \\to q\\) and \\(q \\to p\\) must hold.\n\nIf you read \\(p \\leftrightarrow q\\) aloud, it means:\nâ€œ\\(p\\) is true exactly when \\(q\\) is true.â€ or â€œ\\(p\\) holds exactly when \\(q\\) holds.â€\n\nThis is why mathematicians often use â€œiffâ€ (â€œif and only ifâ€) in definitions and theorems:\n- It guarantees not only that \\(p\\) implies \\(q\\), but also that \\(q\\) implies \\(p\\).\n\nWhy is this important?\n\nIt formalizes definitions in mathematics.\n\nExample: â€œA number \\(n\\) is even iff \\(n = 2k\\) for some integer \\(k\\).â€\n\nThis captures both directions: every even number has that form, and every number of that form is even.\n\nIt allows us to state equivalence theorems.\n\nExample: â€œA sequence is Cauchy iff it is convergent (in \\(\\mathbb{R}\\)).â€\n\nThe biconditional captures the deep connection: each property implies the other.\n\nIt makes reasoning reversible.\n\nWith an implication, you can only go forward (\\(p \\to q\\)).\n\nWith a biconditional, you can go forward and backward: knowing either \\(p\\) or \\(q\\) tells you the other.\n\n\nBy mastering the biconditional, the reader understands why mathematicians love the phrase â€œif and only ifâ€: itâ€™s the precise way of stating true equivalence between concepts.\nSummary Table of Connectives\n\n\n\n\n\n\n\n\nConnective\nSymbol\nRule (when true)\n\n\n\n\nNegation\n\\(\\lnot p\\)\nwhen \\(p\\) is false\n\n\nConjunction\n\\(p \\land q\\)\nwhen \\(p\\) and \\(q\\) are true\n\n\nDisjunction\n\\(p \\lor q\\)\nwhen at least one of \\(p, q\\) is true\n\n\nConditional\n\\(p \\to q\\)\nfalse only if \\(p\\) true and \\(q\\) false\n\n\nBiconditional\n\\(p \\leftrightarrow q\\)\nwhen \\(p\\) and \\(q\\) have same truth value",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#tautologies-contradictions-and-logical-equivalence",
    "href": "chapters/01_ch01.html#tautologies-contradictions-and-logical-equivalence",
    "title": "Phase 1: Logic & Set Theory",
    "section": "1.3 Tautologies, Contradictions, and Logical Equivalence",
    "text": "1.3 Tautologies, Contradictions, and Logical Equivalence\nTautology\nDefinition:\nA tautology is a statement that is true in all possible cases.\nWhy it matters:\n- Tautologies act like universal truths: they donâ€™t depend on data or assumptions.\n- They are often the â€œglueâ€ of proofs, showing that certain forms are always valid.\n- Many rules of inference (like modus ponens) are based on tautologies.\nExample (logic):\n\\[\n(p \\land q) \\to p\n\\]\nThis means: If both (p) and (q) are true, then (p) is true.\n- Always true, regardless of whether (p) or (q) are true or false.\nExample (statistics):\nThe Law of Total Probability is tautological:\n\\[\nP(A) = P(A \\cap B) + P(A \\cap \\lnot B).\n\\]\nThis identity always holds by construction, no matter what events (A) and (B) are.\n\nContradiction\nDefinition:\nA contradiction is a statement that is false in all possible cases.\nWhy it matters:\n- Contradictions are the engine of proof by contradiction.\n- If assuming something leads to a contradiction, then the assumption must be false.\n- They represent â€œimpossible situationsâ€ in logic.\nExample (logic):\n\\[\np \\land \\lnot p\n\\]\nThis means: (p) is true and (p) is false at the same time.\n- Always false, no matter what truth value (p) has.\nExample (statistics):\nSuppose we assume:\n1. â€œThe variance of this distribution is finite.â€\n2. â€œThe variance of this distribution is infinite.â€\nTogether, these form a contradiction, so at least one assumption must be wrong.\n\nLogical Equivalence\nDefinition:\nTwo statements are logically equivalent if they have the same truth value in all possible cases.\nWhy it matters:\n- Logical equivalence lets us replace one statement with another in a proof.\n- Many powerful proof strategies rely on equivalence (contrapositive law, De Morganâ€™s laws, distributive laws).\n- Often the equivalent form is much easier to work with.\nExample (logic):\n\\[\np \\to q \\;\\equiv\\; \\lnot p \\lor q\n\\]\nThis means: â€œIf (p), then (q)â€ is the same as â€œEither not (p), or (q).â€\n- This equivalence makes it easier to manipulate conditionals in proofs.\nExample (causal inference):\n\\[\n\\text{Ignorability} \\to \\text{Identifiability}\n\\]\nis logically equivalent to\n\\[\n\\lnot \\text{Identifiability} \\to \\lnot \\text{Ignorability}.\n\\]\nSwitching to the contrapositive often makes a proof or argument simpler.\n\nSummary:\n- Tautologies give us universal truths to rely on.\n- Contradictions allow us to eliminate false assumptions through contradiction proofs.\n- Logical equivalence lets us restate problems in easier forms without changing meaning.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#predicates-and-quantifiers",
    "href": "chapters/01_ch01.html#predicates-and-quantifiers",
    "title": "Phase 1: Logic & Set Theory",
    "section": "2.1 Predicates and Quantifiers",
    "text": "2.1 Predicates and Quantifiers\nAs we saw above, a predicate is like a sentence with a â€œblankâ€ â€” it becomes a full statement only once you plug in a value.\n\nExample: \\(P(x): x &gt; 0\\).\n\nIf \\(x = 2\\), then \\(P(2)\\) is the proposition â€œ2 &gt; 0â€ (true).\n\nIf \\(x = -3\\), then \\(P(-3)\\) is the proposition â€œ-3 &gt; 0â€ (false).\n\n\nWe use quantifiers to talk about how many elements satisfy a predicate:\n\nUniversal quantifier (\\(\\forall\\)):\n\\(\\forall x\\; P(x)\\) means â€œfor all \\(x\\), \\(P(x)\\) is true.â€\nExistential quantifier (\\(\\exists\\)):\n\\(\\exists x\\; P(x)\\) means â€œthere exists at least one \\(x\\) such that \\(P(x)\\) is true.â€\n\nExamples:\n- \\(\\forall x \\in \\mathbb{Z},\\; x^2 \\geq 0\\). (Every integer squared is nonnegative.)\n- \\(\\exists x \\in \\mathbb{Z},\\; x^2 = 9\\). (There exists an integer whose square is 9.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#universe-of-discourse",
    "href": "chapters/01_ch01.html#universe-of-discourse",
    "title": "Phase 1: Logic & Set Theory",
    "section": "2.2 Universe of Discourse",
    "text": "2.2 Universe of Discourse\nThe universe of discourse is the set of objects we allow \\(x\\) to vary over.\nThe truth of a statement depends on it!\nExample:\n\n\\(\\forall x \\in \\mathbb{R},\\; x^2 \\geq 0\\) is true.\n\n\\(\\forall x \\in \\mathbb{Z},\\; x^2 = 2\\) is false (no integer squared equals 2).\n\nIf we didnâ€™t specify whether \\(x\\) ranges over \\(\\mathbb{R}\\) or \\(\\mathbb{Z}\\) (both interpreted as the universe of discourse of each statement), the meaning would be ambiguous.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#truth-of-quantified-statements",
    "href": "chapters/01_ch01.html#truth-of-quantified-statements",
    "title": "Phase 1: Logic & Set Theory",
    "section": "2.3 Truth of Quantified Statements",
    "text": "2.3 Truth of Quantified Statements\nHow to evaluate quantified statements:\n\n\\(\\forall x\\; P(x)\\) is true if every \\(x\\) in the universe makes \\(P(x)\\) true.\n\n\\(\\exists x\\; P(x)\\) is true if at least one \\(x\\) makes \\(P(x)\\) true.\n\n\nNegations of Quantifiers\nNegating quantified statements flips the quantifier:\n\\[\n\\lnot (\\forall x\\, P(x)) \\equiv \\exists x\\, \\lnot P(x)\n\\]\n\\[\n\\lnot (\\exists x\\, P(x)) \\equiv \\forall x\\, \\lnot P(x)\n\\]\nExamples:\n\nâ€œNot all students passedâ€ means â€œThere exists a student who did not pass.â€\n\nâ€œThere does not exist a unicornâ€ means â€œFor all \\(x\\), \\(x\\) is not a unicorn.â€",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#multiple-quantifiers",
    "href": "chapters/01_ch01.html#multiple-quantifiers",
    "title": "Phase 1: Logic & Set Theory",
    "section": "2.4 Multiple Quantifiers",
    "text": "2.4 Multiple Quantifiers\nOften statements involve more than one quantifier.\nThe order matters!\n\n\\(\\forall x \\in \\mathbb{R},\\; \\exists y \\in \\mathbb{R}: y &gt; x\\)\nâ†’ True, because for every real number \\(x\\), we can pick \\(y = x+1\\).\n\\(\\exists y \\in \\mathbb{R},\\; \\forall x \\in \\mathbb{R}: y &gt; x\\)\nâ†’ False, because no single real number is greater than all real numbers.\n\nTip: Think of quantifiers as a kind of game:\n- For \\(\\forall x\\), your opponent chooses the worst possible \\(x\\).\n- For \\(\\exists y\\), you get to respond by picking a suitable \\(y\\).\nThe order decides who gets to â€œmoveâ€ first, and the outcome can change completely.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#why-this-matters",
    "href": "chapters/01_ch01.html#why-this-matters",
    "title": "Phase 1: Logic & Set Theory",
    "section": "2.5 Why This Matters",
    "text": "2.5 Why This Matters\nQuantifiers appear in almost every mathematical theorem.\n\nAnalysis (limits):\n\\[\n\\forall \\epsilon &gt; 0,\\; \\exists \\delta &gt; 0:\\; |x - a| &lt; \\delta \\;\\to\\; |f(x) - L| &lt; \\epsilon\n\\]\n(â€œFor every tolerance \\(\\epsilon\\), there exists a closeness \\(\\delta\\) that guarantees the function stays within that tolerance.â€)\nStatistics:\n\n\\(\\forall n,\\; \\exists \\hat{\\theta}_n:\\; \\hat{\\theta}_n \\to \\theta\\) (There exists an estimator consistent for \\(\\theta\\).)\n\n\\(\\exists\\) an unbiased estimator of \\(\\mu\\) (the sample mean).\n\nCausal Inference:\n\n\\(\\forall\\) randomized experiments, \\(\\exists\\) an unbiased estimator of the treatment effect.\n\n\nQuantifiers are the way mathematics formalizes sweeping claims like â€œalwaysâ€ and â€œsometimes,â€ which are at the heart of proofs and assumptions in Causal ML.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#exercises",
    "href": "chapters/01_ch01.html#exercises",
    "title": "Phase 1: Logic & Set Theory",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\n\nDecide whether each statement is true or false (universe of discourse: \\(\\mathbb{Z}\\)):\n\n\\(\\forall x,\\; x^2 \\geq 0\\)\n\n\\(\\exists x,\\; x^2 = 2\\)\n\nNegate the following statements and simplify:\n\n\\(\\forall x \\in \\mathbb{R},\\; x^2 \\geq 0\\)\n\n\\(\\exists x \\in \\mathbb{N},\\; x^2 = 2\\)\n\nShow that the order of quantifiers matters by proving:\n\n\\(\\forall x \\in \\mathbb{R},\\; \\exists y \\in \\mathbb{R}: y &gt; x\\) is true.\n\n\\(\\exists y \\in \\mathbb{R},\\; \\forall x \\in \\mathbb{R}: y &gt; x\\) is false.\n\nWrite in logical symbols:\n\nâ€œEvery dataset has at least one outlier.â€\n\nâ€œThere exists a consistent estimator for every parameter.â€",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  },
  {
    "objectID": "chapters/01_ch01.html#references",
    "href": "chapters/01_ch01.html#references",
    "title": "Phase 1: Logic & Set Theory",
    "section": "References",
    "text": "References\n\nVelleman, D. J. (2006). How to Prove It: A Structured Approach.\n\nRosen, K. H. (2011). Discrete Mathematics and Its Applications.\n\nSpanos, A. (1999, 2010). Probability Theory and Statistical Inference.",
    "crumbs": [
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Phase 1: Logic & Set Theory</span>"
    ]
  }
]